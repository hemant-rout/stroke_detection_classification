{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8596dc0",
   "metadata": {},
   "source": [
    "# ğŸ©º Stroke Prediction: End-to-End Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c8c5f5",
   "metadata": {},
   "source": [
    "# 1. Import Libraries\n",
    "Import all necessary libraries for data processing, modeling, and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0786aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\env_test\\vnv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score,cross_val_predict\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler,RobustScaler\n",
    "from sklearn.metrics import f1_score, classification_report,ConfusionMatrixDisplay, confusion_matrix,roc_auc_score,roc_curve, auc\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import StackingClassifier,RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8682e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4807b55",
   "metadata": {},
   "source": [
    "**Tensorflow imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d8ceb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c03c0ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration file for paths and constants\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from config import DATA_RAW_PATH, DATA_PREDICTED_PATH,DATA_PROCESSED_PATH, MODEL_DIR, TRAIN_FILE, TEST_FILE,TRAIN_PREPROCESSED_FILE,TEST_PREPROCESSED_FILE, SAMPLE_SUBMISSION_FILE, RANDOM_STATE,SCALING_FILE_NAME\n",
    "from src.file_handler import FileHandler\n",
    "from src.data_processing import DataPreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9651b7e3",
   "metadata": {},
   "source": [
    "## 2. Dataset Meta Information\n",
    "\n",
    "**Files:**\n",
    "- `train.csv`: Data containing all available features and the stroke response.\n",
    "- `test.csv`: Unseen stroke patients with all available predictors but missing stroke. Used for model prediction.\n",
    "- `sample_submission.csv`: A sample submission file in the correct format.\n",
    "\n",
    "**Data Dictionary:**\n",
    "| Column            | Type     | Description                                                                                 | Values/Range                        |\n",
    "|-------------------|----------|---------------------------------------------------------------------------------------------|-------------------------------------|\n",
    "| `id`              | Integer  | Unique identifier for each record                                                            | Any integer                         |\n",
    "| `gender`          | String   | Gender of the patient                                                                       | `Male`, `Female`                    |\n",
    "| `age`             | Float    | Age of the patient in years                                                                 | Any positive float                  |\n",
    "| `hypertension`    | Integer  | Indicates whether the patient has hypertension                                              | `0`: No, `1`: Yes                   |\n",
    "| `heart_disease`   | Integer  | Indicates whether the patient has heart disease                                             | `0`: No, `1`: Yes                   |\n",
    "| `ever_married`    | String   | Marital status of the patient                                                               | `Yes`, `No`                         |\n",
    "| `work_type`       | String   | Type of employment                                                                          | `Private`, `Self-employed`, `Govt_job`, `Children`, etc. |\n",
    "| `Residence_type`  | String   | Type of residence                                                                          | `Urban`, `Rural`                    |\n",
    "| `avg_glucose_level`| Float   | Average glucose level of the patient (mg/dL)                                                | Any positive float                  |\n",
    "| `bmi`             | Float    | Body Mass Index (BMI) of the patient                                                        | Any positive float                  |\n",
    "| `smoking_status`  | String   | Smoking status                                                                             | `never smoked`, `formerly smoked`, `smokes`, `Unknown` |\n",
    "| `stroke`          | Integer  | Target variable indicating whether the patient had a stroke (**[TARGET]**)                  | `0`: No, `1`: Yes                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a54ddc8",
   "metadata": {},
   "source": [
    "# 3. Load Data\n",
    " Load training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e37d869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train = FileHandler.read_data(DATA_RAW_PATH, TRAIN_FILE)\n",
    "# Load the test data\n",
    "test = FileHandler.read_data(DATA_RAW_PATH, TEST_FILE)\n",
    "# Load the sample submission file\n",
    "sample_solution = FileHandler.read_data(DATA_RAW_PATH, SAMPLE_SUBMISSION_FILE)\n",
    "\n",
    "# Create copies of the original train and test data\n",
    "# This is useful for keeping the original data intact for future reference or comparisons\n",
    "orgnigal_train=train.copy(deep=True)\n",
    "orgnigal_test=test.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec295fb8",
   "metadata": {},
   "source": [
    "# 4. Categorizing features based on data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9dac653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical and numerical columns\n",
    "# These lists categorize the features based on their data types\n",
    "cat_cols = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "cat_binary_cols = ['hypertension', 'heart_disease']\n",
    "num_cols= ['age', 'avg_glucose_level', 'bmi']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b376216",
   "metadata": {},
   "source": [
    "# 5. Data Preprocessing\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f869e9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train and test data for preprocessing\n",
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "test['stroke'] = np.nan\n",
    "full_data = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86f34097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in 'bmi' with the median and 'smoking_status' with 'Unknown'\n",
    "full_data['bmi'] = full_data['bmi'].fillna(full_data['bmi'].median())\n",
    "full_data['smoking_status'] = full_data['smoking_status'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1874614b",
   "metadata": {},
   "source": [
    "# 6. Feature Engineering\n",
    "**Encode categorical variables using One HOT Encodering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ceff124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map binary categorical variables to numerical values\n",
    "binary_map = {'Yes': 1, 'No': 0, 'Urban': 1, 'Rural': 0}\n",
    "#,'Male':1,'Female':0,'Other':0\n",
    "full_data['ever_married'] = full_data['ever_married'].map(binary_map)\n",
    "full_data['Residence_type'] = full_data['Residence_type'].map(binary_map)\n",
    "# full_data['gender'] = full_data['gender'].map(binary_map)\n",
    "\n",
    "# one_hot_encode_features=['work_type', 'smoking_status']\n",
    "one_hot_encode_features=['gender', 'work_type', 'smoking_status']\n",
    "# One-hot encode categorical variables\n",
    "full_data = pd.get_dummies(full_data, columns=one_hot_encode_features, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2eed453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "      <th>is_train</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>gender_Other</th>\n",
       "      <th>work_type_Never_worked</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88.10</td>\n",
       "      <td>29.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80.07</td>\n",
       "      <td>38.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>89.11</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81.36</td>\n",
       "      <td>36.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82.59</td>\n",
       "      <td>29.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   age  hypertension  heart_disease  ever_married  Residence_type  \\\n",
       "0   1  50.0             0              0             1               0   \n",
       "1   2  52.0             0              0             1               0   \n",
       "2   3  26.0             0              0             0               1   \n",
       "3   4  37.0             0              0             1               0   \n",
       "4   5  59.0             0              0             1               0   \n",
       "\n",
       "   avg_glucose_level   bmi  stroke  is_train  gender_Male  gender_Other  \\\n",
       "0              88.10  29.1     0.0         1         True         False   \n",
       "1              80.07  38.9     0.0         1        False         False   \n",
       "2              89.11  23.3     0.0         1        False         False   \n",
       "3              81.36  36.1     0.0         1        False         False   \n",
       "4              82.59  29.6     1.0         1         True         False   \n",
       "\n",
       "   work_type_Never_worked  work_type_Private  work_type_Self-employed  \\\n",
       "0                   False               True                    False   \n",
       "1                   False               True                    False   \n",
       "2                   False              False                    False   \n",
       "3                   False               True                    False   \n",
       "4                   False               True                    False   \n",
       "\n",
       "   work_type_children  smoking_status_formerly smoked  \\\n",
       "0               False                            True   \n",
       "1               False                           False   \n",
       "2               False                           False   \n",
       "3               False                           False   \n",
       "4               False                           False   \n",
       "\n",
       "   smoking_status_never smoked  smoking_status_smokes  \n",
       "0                        False                  False  \n",
       "1                        False                   True  \n",
       "2                        False                   True  \n",
       "3                         True                  False  \n",
       "4                         True                  False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the processed data\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be81eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the combined data back into train and test sets.len. 'is_train' column indicates whether the row is from the training set (1) or\n",
    "train = full_data[full_data['is_train'] == 1].drop(['is_train'], axis=1)\n",
    "test = full_data[full_data['is_train'] == 0].drop(['is_train', 'stroke'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a8630f",
   "metadata": {},
   "source": [
    "# 7. Feature Selection\n",
    "**Select features for modeling (exclude 'id' and 'stroke')**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "626c2c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in train.columns if col not in ['id', 'stroke']]\n",
    "X = train[features]\n",
    "y = train['stroke'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e157d2f1",
   "metadata": {},
   "source": [
    "# 8. Handle Class Imbalance\n",
    "**Apply SMOTE to balance the target classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bf3f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=RANDOM_STATE, sampling_strategy='minority')\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c34aad",
   "metadata": {},
   "source": [
    "# 9. functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26bf4693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(scaler,X_train, X_val, X_test,features=['bmi', 'avg_glucose_level']):\n",
    "    \"\"\"\n",
    "    Scales features using defined scaler. Returns scaled train, val, and optionally test sets.\n",
    "    \"\"\"\n",
    "    # scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train[features])\n",
    "    X_val_scaled = scaler.transform(X_val[features])\n",
    "    # if X_test is not None:\n",
    "    X_test_scaled = scaler.transform(X_test[features])\n",
    "\n",
    "    return X_train_scaled, X_val_scaled, X_test_scaled, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4a1cb8",
   "metadata": {},
   "source": [
    "# 10. Train/Validation Split\n",
    "**Split the resampled data into training and validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "346eb2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val=DataPreprocessor.split_data(X_resampled, y_resampled, test_size=0.2,stratify=y_resampled, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4849ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim,learning_rate=0.0005):\n",
    "    \"\"\"\n",
    "    Build and compile a simple deep neural network for binary classification.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=input_dim))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['AUC', 'accuracy','f1_score'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcfedbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val,\n",
    "                epochs=50, batch_size=32, verbose=1):\n",
    "    \"\"\"\n",
    "    Train the Keras model on the provided data.\n",
    "    \"\"\"\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=verbose)\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52382d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_model(model, X_val, y_val):\n",
    "#     \"\"\"\n",
    "#     Evaluate the trained model and return F1 and ROC-AUC scores.\n",
    "#     \"\"\"\n",
    "#     y_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
    "#     f1 = f1_score(y_val, y_pred)\n",
    "#     roc_auc = roc_auc_score(y_val, y_pred)\n",
    "#     return f1, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c5b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deep_model(X_train,y_train, X_val,y_val):\n",
    "\n",
    "    # Class Weights\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weight = dict(zip(np.unique(y_train), weights))\n",
    "\n",
    "    # Callbacks\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "    model = build_model(X_train.shape[1])\n",
    "    history=model.fit(X_train, y_train,\n",
    "              validation_data=(X_val, y_val),\n",
    "              epochs=100,\n",
    "              batch_size=32,\n",
    "              class_weight=class_weight,\n",
    "              callbacks=[early_stop, lr_scheduler],\n",
    "              verbose=1)\n",
    "\n",
    "    # Print losses\n",
    "    # print(\"\\nTraining/Validation Loss per Epoch:\")\n",
    "    # for epoch, (train_loss, val_loss) in enumerate(\n",
    "    #     zip(history.history['loss'], history.history['val_loss']), 1):\n",
    "    #     print(f\"Epoch {epoch:03d}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58163aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaludate_model(model,X_val,y_val):\n",
    "    y_pred_proba = model.predict(X_val).ravel()\n",
    "    thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "    best_f1, best_thresh = 0, 0.5\n",
    "    for t in thresholds:\n",
    "        f1 = f1_score(y_val, (y_pred_proba > t).astype(int))\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_thresh = f1, t\n",
    "\n",
    "    final_f1 = f1_score(y_val, (y_pred_proba > best_thresh).astype(int))\n",
    "    roc = roc_auc_score(y_val, y_pred_proba)\n",
    "    print(f\"Best Threshold: {best_thresh:.2f} | F1 Score: {final_f1:.4f} | ROC AUC: {roc:.4f}\")\n",
    "    return model, best_thresh,final_f1,roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dbb8f8",
   "metadata": {},
   "source": [
    "# Train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "100ef220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - AUC: 0.8500 - accuracy: 0.7744 - f1_score: 0.6685 - loss: 0.5112 - val_AUC: 0.9325 - val_accuracy: 0.8149 - val_f1_score: 0.6743 - val_loss: 0.4052 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9258 - accuracy: 0.8484 - f1_score: 0.6726 - loss: 0.3516 - val_AUC: 0.9491 - val_accuracy: 0.8202 - val_f1_score: 0.6743 - val_loss: 0.4025 - learning_rate: 5.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9354 - accuracy: 0.8562 - f1_score: 0.6636 - loss: 0.3254 - val_AUC: 0.9555 - val_accuracy: 0.8807 - val_f1_score: 0.6743 - val_loss: 0.2722 - learning_rate: 5.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9424 - accuracy: 0.8673 - f1_score: 0.6681 - loss: 0.3059 - val_AUC: 0.9532 - val_accuracy: 0.8354 - val_f1_score: 0.6743 - val_loss: 0.3517 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9424 - accuracy: 0.8627 - f1_score: 0.6681 - loss: 0.3051 - val_AUC: 0.9559 - val_accuracy: 0.8829 - val_f1_score: 0.6743 - val_loss: 0.2697 - learning_rate: 5.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9460 - accuracy: 0.8703 - f1_score: 0.6637 - loss: 0.2959 - val_AUC: 0.9527 - val_accuracy: 0.8705 - val_f1_score: 0.6743 - val_loss: 0.2870 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9429 - accuracy: 0.8644 - f1_score: 0.6598 - loss: 0.3037 - val_AUC: 0.9542 - val_accuracy: 0.8581 - val_f1_score: 0.6743 - val_loss: 0.3099 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9454 - accuracy: 0.8670 - f1_score: 0.6695 - loss: 0.2979 - val_AUC: 0.9564 - val_accuracy: 0.8807 - val_f1_score: 0.6743 - val_loss: 0.2653 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9486 - accuracy: 0.8728 - f1_score: 0.6624 - loss: 0.2890 - val_AUC: 0.9558 - val_accuracy: 0.8824 - val_f1_score: 0.6743 - val_loss: 0.2721 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9501 - accuracy: 0.8718 - f1_score: 0.6634 - loss: 0.2840 - val_AUC: 0.9523 - val_accuracy: 0.8239 - val_f1_score: 0.6743 - val_loss: 0.3533 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9484 - accuracy: 0.8696 - f1_score: 0.6619 - loss: 0.2886 - val_AUC: 0.9574 - val_accuracy: 0.8809 - val_f1_score: 0.6743 - val_loss: 0.2659 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9514 - accuracy: 0.8762 - f1_score: 0.6658 - loss: 0.2793 - val_AUC: 0.9579 - val_accuracy: 0.8784 - val_f1_score: 0.6743 - val_loss: 0.2902 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9483 - accuracy: 0.8739 - f1_score: 0.6640 - loss: 0.2897 - val_AUC: 0.9482 - val_accuracy: 0.8411 - val_f1_score: 0.6743 - val_loss: 0.3584 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9524 - accuracy: 0.8810 - f1_score: 0.6664 - loss: 0.2778 - val_AUC: 0.9586 - val_accuracy: 0.8867 - val_f1_score: 0.6743 - val_loss: 0.2595 - learning_rate: 2.5000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9460 - accuracy: 0.8690 - f1_score: 0.6605 - loss: 0.2949 - val_AUC: 0.9574 - val_accuracy: 0.8822 - val_f1_score: 0.6743 - val_loss: 0.2803 - learning_rate: 2.5000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9543 - accuracy: 0.8791 - f1_score: 0.6694 - loss: 0.2725 - val_AUC: 0.9587 - val_accuracy: 0.8852 - val_f1_score: 0.6743 - val_loss: 0.2603 - learning_rate: 2.5000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9522 - accuracy: 0.8776 - f1_score: 0.6614 - loss: 0.2784 - val_AUC: 0.9584 - val_accuracy: 0.8831 - val_f1_score: 0.6743 - val_loss: 0.2736 - learning_rate: 2.5000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9501 - accuracy: 0.8754 - f1_score: 0.6611 - loss: 0.2838 - val_AUC: 0.9577 - val_accuracy: 0.8826 - val_f1_score: 0.6743 - val_loss: 0.2714 - learning_rate: 2.5000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9545 - accuracy: 0.8803 - f1_score: 0.6621 - loss: 0.2716 - val_AUC: 0.9577 - val_accuracy: 0.8831 - val_f1_score: 0.6743 - val_loss: 0.2764 - learning_rate: 2.5000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9520 - accuracy: 0.8744 - f1_score: 0.6628 - loss: 0.2771 - val_AUC: 0.9589 - val_accuracy: 0.8890 - val_f1_score: 0.6743 - val_loss: 0.2572 - learning_rate: 1.2500e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9510 - accuracy: 0.8758 - f1_score: 0.6594 - loss: 0.2805 - val_AUC: 0.9591 - val_accuracy: 0.8899 - val_f1_score: 0.6743 - val_loss: 0.2567 - learning_rate: 1.2500e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9525 - accuracy: 0.8757 - f1_score: 0.6604 - loss: 0.2755 - val_AUC: 0.9589 - val_accuracy: 0.8909 - val_f1_score: 0.6743 - val_loss: 0.2590 - learning_rate: 1.2500e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9549 - accuracy: 0.8822 - f1_score: 0.6697 - loss: 0.2694 - val_AUC: 0.9588 - val_accuracy: 0.8869 - val_f1_score: 0.6743 - val_loss: 0.2626 - learning_rate: 1.2500e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9536 - accuracy: 0.8804 - f1_score: 0.6686 - loss: 0.2731 - val_AUC: 0.9590 - val_accuracy: 0.8897 - val_f1_score: 0.6743 - val_loss: 0.2568 - learning_rate: 1.2500e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9557 - accuracy: 0.8786 - f1_score: 0.6694 - loss: 0.2672 - val_AUC: 0.9586 - val_accuracy: 0.8841 - val_f1_score: 0.6743 - val_loss: 0.2758 - learning_rate: 1.2500e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9527 - accuracy: 0.8781 - f1_score: 0.6595 - loss: 0.2757 - val_AUC: 0.9591 - val_accuracy: 0.8892 - val_f1_score: 0.6743 - val_loss: 0.2571 - learning_rate: 1.2500e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9563 - accuracy: 0.8827 - f1_score: 0.6650 - loss: 0.2649 - val_AUC: 0.9595 - val_accuracy: 0.8863 - val_f1_score: 0.6743 - val_loss: 0.2551 - learning_rate: 6.2500e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9561 - accuracy: 0.8832 - f1_score: 0.6636 - loss: 0.2647 - val_AUC: 0.9594 - val_accuracy: 0.8920 - val_f1_score: 0.6743 - val_loss: 0.2550 - learning_rate: 6.2500e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9514 - accuracy: 0.8720 - f1_score: 0.6660 - loss: 0.2792 - val_AUC: 0.9590 - val_accuracy: 0.8909 - val_f1_score: 0.6743 - val_loss: 0.2583 - learning_rate: 6.2500e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9513 - accuracy: 0.8723 - f1_score: 0.6645 - loss: 0.2781 - val_AUC: 0.9589 - val_accuracy: 0.8922 - val_f1_score: 0.6743 - val_loss: 0.2607 - learning_rate: 6.2500e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9525 - accuracy: 0.8767 - f1_score: 0.6633 - loss: 0.2761 - val_AUC: 0.9594 - val_accuracy: 0.8920 - val_f1_score: 0.6743 - val_loss: 0.2566 - learning_rate: 6.2500e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9528 - accuracy: 0.8756 - f1_score: 0.6649 - loss: 0.2747 - val_AUC: 0.9592 - val_accuracy: 0.8888 - val_f1_score: 0.6743 - val_loss: 0.2609 - learning_rate: 6.2500e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9547 - accuracy: 0.8791 - f1_score: 0.6684 - loss: 0.2707 - val_AUC: 0.9593 - val_accuracy: 0.8895 - val_f1_score: 0.6743 - val_loss: 0.2603 - learning_rate: 6.2500e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9562 - accuracy: 0.8825 - f1_score: 0.6680 - loss: 0.2658 - val_AUC: 0.9594 - val_accuracy: 0.8916 - val_f1_score: 0.6743 - val_loss: 0.2560 - learning_rate: 3.1250e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9537 - accuracy: 0.8814 - f1_score: 0.6616 - loss: 0.2722 - val_AUC: 0.9593 - val_accuracy: 0.8920 - val_f1_score: 0.6743 - val_loss: 0.2562 - learning_rate: 3.1250e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9547 - accuracy: 0.8792 - f1_score: 0.6623 - loss: 0.2687 - val_AUC: 0.9594 - val_accuracy: 0.8916 - val_f1_score: 0.6743 - val_loss: 0.2553 - learning_rate: 3.1250e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9541 - accuracy: 0.8800 - f1_score: 0.6681 - loss: 0.2715 - val_AUC: 0.9594 - val_accuracy: 0.8897 - val_f1_score: 0.6743 - val_loss: 0.2545 - learning_rate: 3.1250e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9540 - accuracy: 0.8781 - f1_score: 0.6620 - loss: 0.2712 - val_AUC: 0.9594 - val_accuracy: 0.8905 - val_f1_score: 0.6743 - val_loss: 0.2564 - learning_rate: 3.1250e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9561 - accuracy: 0.8803 - f1_score: 0.6573 - loss: 0.2658 - val_AUC: 0.9593 - val_accuracy: 0.8916 - val_f1_score: 0.6743 - val_loss: 0.2560 - learning_rate: 3.1250e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9529 - accuracy: 0.8780 - f1_score: 0.6629 - loss: 0.2743 - val_AUC: 0.9593 - val_accuracy: 0.8914 - val_f1_score: 0.6743 - val_loss: 0.2567 - learning_rate: 3.1250e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9558 - accuracy: 0.8807 - f1_score: 0.6639 - loss: 0.2661 - val_AUC: 0.9595 - val_accuracy: 0.8907 - val_f1_score: 0.6743 - val_loss: 0.2555 - learning_rate: 3.1250e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9554 - accuracy: 0.8826 - f1_score: 0.6653 - loss: 0.2678 - val_AUC: 0.9596 - val_accuracy: 0.8929 - val_f1_score: 0.6743 - val_loss: 0.2539 - learning_rate: 3.1250e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9540 - accuracy: 0.8805 - f1_score: 0.6656 - loss: 0.2720 - val_AUC: 0.9594 - val_accuracy: 0.8899 - val_f1_score: 0.6743 - val_loss: 0.2575 - learning_rate: 3.1250e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9541 - accuracy: 0.8783 - f1_score: 0.6639 - loss: 0.2710 - val_AUC: 0.9595 - val_accuracy: 0.8918 - val_f1_score: 0.6743 - val_loss: 0.2556 - learning_rate: 3.1250e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9555 - accuracy: 0.8805 - f1_score: 0.6635 - loss: 0.2677 - val_AUC: 0.9594 - val_accuracy: 0.8922 - val_f1_score: 0.6743 - val_loss: 0.2552 - learning_rate: 3.1250e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9535 - accuracy: 0.8787 - f1_score: 0.6618 - loss: 0.2727 - val_AUC: 0.9594 - val_accuracy: 0.8916 - val_f1_score: 0.6743 - val_loss: 0.2561 - learning_rate: 3.1250e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9545 - accuracy: 0.8778 - f1_score: 0.6671 - loss: 0.2702 - val_AUC: 0.9595 - val_accuracy: 0.8912 - val_f1_score: 0.6743 - val_loss: 0.2549 - learning_rate: 3.1250e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9544 - accuracy: 0.8821 - f1_score: 0.6691 - loss: 0.2707 - val_AUC: 0.9595 - val_accuracy: 0.8924 - val_f1_score: 0.6743 - val_loss: 0.2555 - learning_rate: 1.5625e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9568 - accuracy: 0.8846 - f1_score: 0.6603 - loss: 0.2641 - val_AUC: 0.9596 - val_accuracy: 0.8905 - val_f1_score: 0.6743 - val_loss: 0.2556 - learning_rate: 1.5625e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9565 - accuracy: 0.8814 - f1_score: 0.6678 - loss: 0.2644 - val_AUC: 0.9595 - val_accuracy: 0.8920 - val_f1_score: 0.6743 - val_loss: 0.2549 - learning_rate: 1.5625e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9547 - accuracy: 0.8801 - f1_score: 0.6679 - loss: 0.2708 - val_AUC: 0.9594 - val_accuracy: 0.8903 - val_f1_score: 0.6743 - val_loss: 0.2559 - learning_rate: 1.5625e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9535 - accuracy: 0.8760 - f1_score: 0.6643 - loss: 0.2726 - val_AUC: 0.9595 - val_accuracy: 0.8920 - val_f1_score: 0.6743 - val_loss: 0.2548 - learning_rate: 1.5625e-05\n",
      "\n",
      "Training/Validation Loss per Epoch:\n",
      "Epoch 001: train_loss=0.4468 | val_loss=0.4052\n",
      "Epoch 002: train_loss=0.3405 | val_loss=0.4025\n",
      "Epoch 003: train_loss=0.3202 | val_loss=0.2722\n",
      "Epoch 004: train_loss=0.3084 | val_loss=0.3517\n",
      "Epoch 005: train_loss=0.3037 | val_loss=0.2697\n",
      "Epoch 006: train_loss=0.2979 | val_loss=0.2870\n",
      "Epoch 007: train_loss=0.2971 | val_loss=0.3099\n",
      "Epoch 008: train_loss=0.2990 | val_loss=0.2653\n",
      "Epoch 009: train_loss=0.2893 | val_loss=0.2721\n",
      "Epoch 010: train_loss=0.2930 | val_loss=0.3533\n",
      "Epoch 011: train_loss=0.2891 | val_loss=0.2659\n",
      "Epoch 012: train_loss=0.2836 | val_loss=0.2902\n",
      "Epoch 013: train_loss=0.2881 | val_loss=0.3584\n",
      "Epoch 014: train_loss=0.2845 | val_loss=0.2595\n",
      "Epoch 015: train_loss=0.2848 | val_loss=0.2803\n",
      "Epoch 016: train_loss=0.2798 | val_loss=0.2603\n",
      "Epoch 017: train_loss=0.2803 | val_loss=0.2736\n",
      "Epoch 018: train_loss=0.2795 | val_loss=0.2714\n",
      "Epoch 019: train_loss=0.2777 | val_loss=0.2764\n",
      "Epoch 020: train_loss=0.2766 | val_loss=0.2572\n",
      "Epoch 021: train_loss=0.2774 | val_loss=0.2567\n",
      "Epoch 022: train_loss=0.2741 | val_loss=0.2590\n",
      "Epoch 023: train_loss=0.2678 | val_loss=0.2626\n",
      "Epoch 024: train_loss=0.2714 | val_loss=0.2568\n",
      "Epoch 025: train_loss=0.2711 | val_loss=0.2758\n",
      "Epoch 026: train_loss=0.2722 | val_loss=0.2571\n",
      "Epoch 027: train_loss=0.2689 | val_loss=0.2551\n",
      "Epoch 028: train_loss=0.2681 | val_loss=0.2550\n",
      "Epoch 029: train_loss=0.2748 | val_loss=0.2583\n",
      "Epoch 030: train_loss=0.2735 | val_loss=0.2607\n",
      "Epoch 031: train_loss=0.2774 | val_loss=0.2566\n",
      "Epoch 032: train_loss=0.2726 | val_loss=0.2609\n",
      "Epoch 033: train_loss=0.2698 | val_loss=0.2603\n",
      "Epoch 034: train_loss=0.2688 | val_loss=0.2560\n",
      "Epoch 035: train_loss=0.2727 | val_loss=0.2562\n",
      "Epoch 036: train_loss=0.2702 | val_loss=0.2553\n",
      "Epoch 037: train_loss=0.2701 | val_loss=0.2545\n",
      "Epoch 038: train_loss=0.2686 | val_loss=0.2564\n",
      "Epoch 039: train_loss=0.2719 | val_loss=0.2560\n",
      "Epoch 040: train_loss=0.2725 | val_loss=0.2567\n",
      "Epoch 041: train_loss=0.2684 | val_loss=0.2555\n",
      "Epoch 042: train_loss=0.2721 | val_loss=0.2539\n",
      "Epoch 043: train_loss=0.2678 | val_loss=0.2575\n",
      "Epoch 044: train_loss=0.2705 | val_loss=0.2556\n",
      "Epoch 045: train_loss=0.2700 | val_loss=0.2552\n",
      "Epoch 046: train_loss=0.2689 | val_loss=0.2561\n",
      "Epoch 047: train_loss=0.2676 | val_loss=0.2549\n",
      "Epoch 048: train_loss=0.2701 | val_loss=0.2555\n",
      "Epoch 049: train_loss=0.2662 | val_loss=0.2556\n",
      "Epoch 050: train_loss=0.2683 | val_loss=0.2549\n",
      "Epoch 051: train_loss=0.2701 | val_loss=0.2559\n",
      "Epoch 052: train_loss=0.2703 | val_loss=0.2548\n",
      "\u001b[1m147/147\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Best Threshold: 0.50 | F1 Score: 0.8932 | ROC AUC: 0.9597\n"
     ]
    }
   ],
   "source": [
    "model=train_deep_model(X_train, y_train,X_val, y_val)\n",
    "final_model, best_thresh,final_f1,roc=evaludate_model(model,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b40be0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features before training models\n",
    "robust_scaler = RobustScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "X_train_scaled, X_val_scaled,X_test,feature_scaler = scale_features(standard_scaler,X_train, X_val,test,features=['bmi', 'avg_glucose_level'])\n",
    "# save_pickle_file(feature_scaler, SCALING_FILE_NAME,MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a655bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - AUC: 0.6210 - accuracy: 0.5760 - f1_score: 0.6622 - loss: 0.7299 - val_AUC: 0.6769 - val_accuracy: 0.6053 - val_f1_score: 0.6743 - val_loss: 0.6255 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6336 - accuracy: 0.5819 - f1_score: 0.6700 - loss: 0.6700 - val_AUC: 0.6880 - val_accuracy: 0.6300 - val_f1_score: 0.6743 - val_loss: 0.6170 - learning_rate: 5.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6593 - accuracy: 0.5996 - f1_score: 0.6640 - loss: 0.6463 - val_AUC: 0.6869 - val_accuracy: 0.6207 - val_f1_score: 0.6743 - val_loss: 0.6186 - learning_rate: 5.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6556 - accuracy: 0.6008 - f1_score: 0.6613 - loss: 0.6427 - val_AUC: 0.6876 - val_accuracy: 0.6247 - val_f1_score: 0.6743 - val_loss: 0.6175 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6644 - accuracy: 0.6045 - f1_score: 0.6613 - loss: 0.6384 - val_AUC: 0.6869 - val_accuracy: 0.6202 - val_f1_score: 0.6743 - val_loss: 0.6184 - learning_rate: 5.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6575 - accuracy: 0.6017 - f1_score: 0.6691 - loss: 0.6404 - val_AUC: 0.6901 - val_accuracy: 0.6211 - val_f1_score: 0.6743 - val_loss: 0.6170 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6690 - accuracy: 0.6112 - f1_score: 0.6637 - loss: 0.6328 - val_AUC: 0.6882 - val_accuracy: 0.6302 - val_f1_score: 0.6743 - val_loss: 0.6165 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6617 - accuracy: 0.6034 - f1_score: 0.6610 - loss: 0.6365 - val_AUC: 0.6889 - val_accuracy: 0.6292 - val_f1_score: 0.6743 - val_loss: 0.6163 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6684 - accuracy: 0.6048 - f1_score: 0.6652 - loss: 0.6366 - val_AUC: 0.6907 - val_accuracy: 0.6222 - val_f1_score: 0.6743 - val_loss: 0.6170 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6738 - accuracy: 0.6168 - f1_score: 0.6672 - loss: 0.6328 - val_AUC: 0.6850 - val_accuracy: 0.6204 - val_f1_score: 0.6743 - val_loss: 0.6183 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6669 - accuracy: 0.6050 - f1_score: 0.6572 - loss: 0.6348 - val_AUC: 0.6904 - val_accuracy: 0.6251 - val_f1_score: 0.6743 - val_loss: 0.6178 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6746 - accuracy: 0.6133 - f1_score: 0.6674 - loss: 0.6320 - val_AUC: 0.6913 - val_accuracy: 0.6298 - val_f1_score: 0.6743 - val_loss: 0.6165 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6751 - accuracy: 0.6148 - f1_score: 0.6664 - loss: 0.6312 - val_AUC: 0.6906 - val_accuracy: 0.6222 - val_f1_score: 0.6743 - val_loss: 0.6165 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6697 - accuracy: 0.6060 - f1_score: 0.6640 - loss: 0.6304 - val_AUC: 0.6916 - val_accuracy: 0.6285 - val_f1_score: 0.6743 - val_loss: 0.6155 - learning_rate: 2.5000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6689 - accuracy: 0.6058 - f1_score: 0.6640 - loss: 0.6325 - val_AUC: 0.6902 - val_accuracy: 0.6266 - val_f1_score: 0.6743 - val_loss: 0.6170 - learning_rate: 2.5000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6703 - accuracy: 0.6085 - f1_score: 0.6617 - loss: 0.6336 - val_AUC: 0.6885 - val_accuracy: 0.6209 - val_f1_score: 0.6743 - val_loss: 0.6173 - learning_rate: 2.5000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6752 - accuracy: 0.6125 - f1_score: 0.6614 - loss: 0.6286 - val_AUC: 0.6928 - val_accuracy: 0.6302 - val_f1_score: 0.6743 - val_loss: 0.6154 - learning_rate: 2.5000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6801 - accuracy: 0.6157 - f1_score: 0.6655 - loss: 0.6267 - val_AUC: 0.6926 - val_accuracy: 0.6292 - val_f1_score: 0.6743 - val_loss: 0.6157 - learning_rate: 2.5000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6760 - accuracy: 0.6122 - f1_score: 0.6647 - loss: 0.6266 - val_AUC: 0.6929 - val_accuracy: 0.6300 - val_f1_score: 0.6743 - val_loss: 0.6165 - learning_rate: 2.5000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6740 - accuracy: 0.6082 - f1_score: 0.6635 - loss: 0.6289 - val_AUC: 0.6930 - val_accuracy: 0.6268 - val_f1_score: 0.6743 - val_loss: 0.6157 - learning_rate: 2.5000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6768 - accuracy: 0.6134 - f1_score: 0.6636 - loss: 0.6291 - val_AUC: 0.6921 - val_accuracy: 0.6307 - val_f1_score: 0.6743 - val_loss: 0.6158 - learning_rate: 2.5000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6671 - accuracy: 0.6030 - f1_score: 0.6584 - loss: 0.6349 - val_AUC: 0.6933 - val_accuracy: 0.6298 - val_f1_score: 0.6743 - val_loss: 0.6151 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6762 - accuracy: 0.6163 - f1_score: 0.6604 - loss: 0.6319 - val_AUC: 0.6944 - val_accuracy: 0.6296 - val_f1_score: 0.6743 - val_loss: 0.6158 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6774 - accuracy: 0.6151 - f1_score: 0.6692 - loss: 0.6258 - val_AUC: 0.6904 - val_accuracy: 0.6155 - val_f1_score: 0.6743 - val_loss: 0.6166 - learning_rate: 2.5000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6765 - accuracy: 0.6098 - f1_score: 0.6652 - loss: 0.6289 - val_AUC: 0.6924 - val_accuracy: 0.6319 - val_f1_score: 0.6743 - val_loss: 0.6153 - learning_rate: 2.5000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6791 - accuracy: 0.6173 - f1_score: 0.6659 - loss: 0.6260 - val_AUC: 0.6931 - val_accuracy: 0.6315 - val_f1_score: 0.6743 - val_loss: 0.6151 - learning_rate: 2.5000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6786 - accuracy: 0.6174 - f1_score: 0.6659 - loss: 0.6282 - val_AUC: 0.6956 - val_accuracy: 0.6262 - val_f1_score: 0.6743 - val_loss: 0.6157 - learning_rate: 2.5000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6711 - accuracy: 0.6067 - f1_score: 0.6654 - loss: 0.6318 - val_AUC: 0.6943 - val_accuracy: 0.6279 - val_f1_score: 0.6743 - val_loss: 0.6148 - learning_rate: 1.2500e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6803 - accuracy: 0.6168 - f1_score: 0.6660 - loss: 0.6266 - val_AUC: 0.6959 - val_accuracy: 0.6298 - val_f1_score: 0.6743 - val_loss: 0.6153 - learning_rate: 1.2500e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6772 - accuracy: 0.6159 - f1_score: 0.6628 - loss: 0.6286 - val_AUC: 0.6935 - val_accuracy: 0.6307 - val_f1_score: 0.6743 - val_loss: 0.6152 - learning_rate: 1.2500e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6728 - accuracy: 0.6155 - f1_score: 0.6680 - loss: 0.6308 - val_AUC: 0.6928 - val_accuracy: 0.6300 - val_f1_score: 0.6743 - val_loss: 0.6152 - learning_rate: 1.2500e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6682 - accuracy: 0.6110 - f1_score: 0.6662 - loss: 0.6330 - val_AUC: 0.6932 - val_accuracy: 0.6319 - val_f1_score: 0.6743 - val_loss: 0.6143 - learning_rate: 1.2500e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6839 - accuracy: 0.6210 - f1_score: 0.6725 - loss: 0.6259 - val_AUC: 0.6954 - val_accuracy: 0.6317 - val_f1_score: 0.6743 - val_loss: 0.6156 - learning_rate: 1.2500e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6833 - accuracy: 0.6224 - f1_score: 0.6641 - loss: 0.6272 - val_AUC: 0.6949 - val_accuracy: 0.6292 - val_f1_score: 0.6743 - val_loss: 0.6150 - learning_rate: 1.2500e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6754 - accuracy: 0.6109 - f1_score: 0.6707 - loss: 0.6289 - val_AUC: 0.6965 - val_accuracy: 0.6300 - val_f1_score: 0.6743 - val_loss: 0.6146 - learning_rate: 1.2500e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6768 - accuracy: 0.6174 - f1_score: 0.6676 - loss: 0.6282 - val_AUC: 0.6951 - val_accuracy: 0.6292 - val_f1_score: 0.6743 - val_loss: 0.6142 - learning_rate: 1.2500e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6803 - accuracy: 0.6203 - f1_score: 0.6669 - loss: 0.6274 - val_AUC: 0.6957 - val_accuracy: 0.6294 - val_f1_score: 0.6743 - val_loss: 0.6153 - learning_rate: 1.2500e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6824 - accuracy: 0.6216 - f1_score: 0.6613 - loss: 0.6262 - val_AUC: 0.6945 - val_accuracy: 0.6324 - val_f1_score: 0.6743 - val_loss: 0.6147 - learning_rate: 6.2500e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6767 - accuracy: 0.6190 - f1_score: 0.6690 - loss: 0.6311 - val_AUC: 0.6948 - val_accuracy: 0.6302 - val_f1_score: 0.6743 - val_loss: 0.6144 - learning_rate: 6.2500e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6826 - accuracy: 0.6172 - f1_score: 0.6694 - loss: 0.6259 - val_AUC: 0.6947 - val_accuracy: 0.6322 - val_f1_score: 0.6743 - val_loss: 0.6143 - learning_rate: 6.2500e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6767 - accuracy: 0.6136 - f1_score: 0.6673 - loss: 0.6292 - val_AUC: 0.6971 - val_accuracy: 0.6290 - val_f1_score: 0.6743 - val_loss: 0.6144 - learning_rate: 6.2500e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6805 - accuracy: 0.6176 - f1_score: 0.6643 - loss: 0.6270 - val_AUC: 0.6950 - val_accuracy: 0.6307 - val_f1_score: 0.6743 - val_loss: 0.6142 - learning_rate: 6.2500e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6750 - accuracy: 0.6173 - f1_score: 0.6651 - loss: 0.6319 - val_AUC: 0.6951 - val_accuracy: 0.6309 - val_f1_score: 0.6743 - val_loss: 0.6144 - learning_rate: 3.1250e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6823 - accuracy: 0.6142 - f1_score: 0.6639 - loss: 0.6266 - val_AUC: 0.6951 - val_accuracy: 0.6307 - val_f1_score: 0.6743 - val_loss: 0.6143 - learning_rate: 3.1250e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6817 - accuracy: 0.6173 - f1_score: 0.6683 - loss: 0.6276 - val_AUC: 0.6956 - val_accuracy: 0.6305 - val_f1_score: 0.6743 - val_loss: 0.6141 - learning_rate: 3.1250e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6814 - accuracy: 0.6192 - f1_score: 0.6620 - loss: 0.6273 - val_AUC: 0.6958 - val_accuracy: 0.6313 - val_f1_score: 0.6743 - val_loss: 0.6145 - learning_rate: 3.1250e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6778 - accuracy: 0.6159 - f1_score: 0.6682 - loss: 0.6290 - val_AUC: 0.6960 - val_accuracy: 0.6313 - val_f1_score: 0.6743 - val_loss: 0.6140 - learning_rate: 3.1250e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6789 - accuracy: 0.6148 - f1_score: 0.6614 - loss: 0.6278 - val_AUC: 0.6957 - val_accuracy: 0.6322 - val_f1_score: 0.6743 - val_loss: 0.6140 - learning_rate: 3.1250e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6804 - accuracy: 0.6178 - f1_score: 0.6690 - loss: 0.6261 - val_AUC: 0.6966 - val_accuracy: 0.6311 - val_f1_score: 0.6743 - val_loss: 0.6141 - learning_rate: 3.1250e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.6805 - accuracy: 0.6198 - f1_score: 0.6645 - loss: 0.6273 - val_AUC: 0.6961 - val_accuracy: 0.6328 - val_f1_score: 0.6743 - val_loss: 0.6140 - learning_rate: 3.1250e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - AUC: 0.6825 - accuracy: 0.6178 - f1_score: 0.6647 - loss: 0.6247 - val_AUC: 0.6948 - val_accuracy: 0.6313 - val_f1_score: 0.6743 - val_loss: 0.6142 - learning_rate: 3.1250e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - AUC: 0.6809 - accuracy: 0.6203 - f1_score: 0.6658 - loss: 0.6254 - val_AUC: 0.6958 - val_accuracy: 0.6311 - val_f1_score: 0.6743 - val_loss: 0.6143 - learning_rate: 3.1250e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - AUC: 0.6823 - accuracy: 0.6148 - f1_score: 0.6616 - loss: 0.6252 - val_AUC: 0.6954 - val_accuracy: 0.6311 - val_f1_score: 0.6743 - val_loss: 0.6141 - learning_rate: 3.1250e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - AUC: 0.6857 - accuracy: 0.6205 - f1_score: 0.6688 - loss: 0.6214 - val_AUC: 0.6962 - val_accuracy: 0.6317 - val_f1_score: 0.6743 - val_loss: 0.6140 - learning_rate: 1.5625e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - AUC: 0.6799 - accuracy: 0.6179 - f1_score: 0.6635 - loss: 0.6259 - val_AUC: 0.6960 - val_accuracy: 0.6315 - val_f1_score: 0.6743 - val_loss: 0.6142 - learning_rate: 1.5625e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - AUC: 0.6838 - accuracy: 0.6224 - f1_score: 0.6647 - loss: 0.6250 - val_AUC: 0.6964 - val_accuracy: 0.6300 - val_f1_score: 0.6743 - val_loss: 0.6143 - learning_rate: 1.5625e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - AUC: 0.6804 - accuracy: 0.6173 - f1_score: 0.6634 - loss: 0.6262 - val_AUC: 0.6968 - val_accuracy: 0.6324 - val_f1_score: 0.6743 - val_loss: 0.6141 - learning_rate: 1.5625e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m587/587\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - AUC: 0.6808 - accuracy: 0.6191 - f1_score: 0.6662 - loss: 0.6269 - val_AUC: 0.6962 - val_accuracy: 0.6322 - val_f1_score: 0.6743 - val_loss: 0.6141 - learning_rate: 1.5625e-05\n",
      "\n",
      "Training/Validation Loss per Epoch:\n",
      "Epoch 001: train_loss=0.7034 | val_loss=0.6255\n",
      "Epoch 002: train_loss=0.6622 | val_loss=0.6170\n",
      "Epoch 003: train_loss=0.6479 | val_loss=0.6186\n",
      "Epoch 004: train_loss=0.6424 | val_loss=0.6175\n",
      "Epoch 005: train_loss=0.6377 | val_loss=0.6184\n",
      "Epoch 006: train_loss=0.6367 | val_loss=0.6170\n",
      "Epoch 007: train_loss=0.6341 | val_loss=0.6165\n",
      "Epoch 008: train_loss=0.6324 | val_loss=0.6163\n",
      "Epoch 009: train_loss=0.6322 | val_loss=0.6170\n",
      "Epoch 010: train_loss=0.6323 | val_loss=0.6183\n",
      "Epoch 011: train_loss=0.6321 | val_loss=0.6178\n",
      "Epoch 012: train_loss=0.6305 | val_loss=0.6165\n",
      "Epoch 013: train_loss=0.6297 | val_loss=0.6165\n",
      "Epoch 014: train_loss=0.6318 | val_loss=0.6155\n",
      "Epoch 015: train_loss=0.6309 | val_loss=0.6170\n",
      "Epoch 016: train_loss=0.6309 | val_loss=0.6173\n",
      "Epoch 017: train_loss=0.6308 | val_loss=0.6154\n",
      "Epoch 018: train_loss=0.6290 | val_loss=0.6157\n",
      "Epoch 019: train_loss=0.6292 | val_loss=0.6165\n",
      "Epoch 020: train_loss=0.6290 | val_loss=0.6157\n",
      "Epoch 021: train_loss=0.6293 | val_loss=0.6158\n",
      "Epoch 022: train_loss=0.6299 | val_loss=0.6151\n",
      "Epoch 023: train_loss=0.6322 | val_loss=0.6158\n",
      "Epoch 024: train_loss=0.6286 | val_loss=0.6166\n",
      "Epoch 025: train_loss=0.6292 | val_loss=0.6153\n",
      "Epoch 026: train_loss=0.6284 | val_loss=0.6151\n",
      "Epoch 027: train_loss=0.6291 | val_loss=0.6157\n",
      "Epoch 028: train_loss=0.6289 | val_loss=0.6148\n",
      "Epoch 029: train_loss=0.6278 | val_loss=0.6153\n",
      "Epoch 030: train_loss=0.6295 | val_loss=0.6152\n",
      "Epoch 031: train_loss=0.6286 | val_loss=0.6152\n",
      "Epoch 032: train_loss=0.6278 | val_loss=0.6143\n",
      "Epoch 033: train_loss=0.6292 | val_loss=0.6156\n",
      "Epoch 034: train_loss=0.6286 | val_loss=0.6150\n",
      "Epoch 035: train_loss=0.6289 | val_loss=0.6146\n",
      "Epoch 036: train_loss=0.6275 | val_loss=0.6142\n",
      "Epoch 037: train_loss=0.6292 | val_loss=0.6153\n",
      "Epoch 038: train_loss=0.6281 | val_loss=0.6147\n",
      "Epoch 039: train_loss=0.6281 | val_loss=0.6144\n",
      "Epoch 040: train_loss=0.6263 | val_loss=0.6143\n",
      "Epoch 041: train_loss=0.6284 | val_loss=0.6144\n",
      "Epoch 042: train_loss=0.6285 | val_loss=0.6142\n",
      "Epoch 043: train_loss=0.6258 | val_loss=0.6144\n",
      "Epoch 044: train_loss=0.6271 | val_loss=0.6143\n",
      "Epoch 045: train_loss=0.6267 | val_loss=0.6141\n",
      "Epoch 046: train_loss=0.6276 | val_loss=0.6145\n",
      "Epoch 047: train_loss=0.6269 | val_loss=0.6140\n",
      "Epoch 048: train_loss=0.6270 | val_loss=0.6140\n",
      "Epoch 049: train_loss=0.6262 | val_loss=0.6141\n",
      "Epoch 050: train_loss=0.6273 | val_loss=0.6140\n",
      "Epoch 051: train_loss=0.6268 | val_loss=0.6142\n",
      "Epoch 052: train_loss=0.6273 | val_loss=0.6143\n",
      "Epoch 053: train_loss=0.6268 | val_loss=0.6141\n",
      "Epoch 054: train_loss=0.6266 | val_loss=0.6140\n",
      "Epoch 055: train_loss=0.6278 | val_loss=0.6142\n",
      "Epoch 056: train_loss=0.6281 | val_loss=0.6143\n",
      "Epoch 057: train_loss=0.6262 | val_loss=0.6141\n",
      "Epoch 058: train_loss=0.6263 | val_loss=0.6141\n",
      "\u001b[1m147/147\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Best Threshold: 0.29 | F1 Score: 0.7045 | ROC AUC: 0.6958\n"
     ]
    }
   ],
   "source": [
    "# on the scaled data, train the deep learning model\n",
    "# This function will train the model and return the trained model, best threshold, final F1 score, and ROC AUC score\n",
    "model=train_deep_model(X_train_scaled, y_train,X_val_scaled, y_val)\n",
    "final_model, best_thresh,final_f1,roc=evaludate_model(model,X_val_scaled,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75552141",
   "metadata": {},
   "source": [
    "# Summary of the model\n",
    "* F1 score is greater than 90%, but we can improve it by tuning the hyperparameters, adding more layers, or using different activation functions.\n",
    "* ROC AUC score is good, which indicates that the model is able to distinguish between the two classes well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732ec5e5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
